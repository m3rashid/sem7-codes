{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.label = None\n",
    "        self.branches = []\n",
    "        self.is_leaf = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.features = None\n",
    "        self.root = None\n",
    "\n",
    "    def getEntropy(self, y):\n",
    "        samples_count = len(y)\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / samples_count\n",
    "        entropy = -np.sum(np.log2(probabilities) * probabilities)\n",
    "        return entropy\n",
    "\n",
    "    def getInfoGain(self, X, y, feature_name):\n",
    "        feature_id = self.features.tolist().index(feature_name)\n",
    "        feature_vals = X[:, feature_id]\n",
    "        unique_feature_vals, counts = np.unique(\n",
    "            feature_vals, return_counts=True)\n",
    "        y_subsets = [\n",
    "            [y[i]\n",
    "             for i, v in enumerate(feature_vals)\n",
    "             if v == uv]\n",
    "            for uv in unique_feature_vals\n",
    "        ]\n",
    "\n",
    "        info_gain_feature = sum([count / len(X) * self.getEntropy(y_subset)\n",
    "                                 for count, y_subset in zip(counts, y_subsets)])\n",
    "        info_gain = self.getEntropy(y) - info_gain_feature\n",
    "        return info_gain\n",
    "\n",
    "    def get_most_informative_feature(self, X, y, feature_names):\n",
    "        info_gains = [self.getInfoGain(X, y, feature_name)\n",
    "                      for feature_name in feature_names]\n",
    "        best_feature_name = feature_names[info_gains.index(max(info_gains))]\n",
    "        return best_feature_name\n",
    "\n",
    "    def decision_tree(self, X, y, feature_names):\n",
    "        node = Node()\n",
    "\n",
    "        # if all the example have the same class (pure node), return node\n",
    "        if len(set(y)) == 1:\n",
    "            node.is_leaf = True\n",
    "            node.label = y[0]\n",
    "            return node\n",
    "\n",
    "        # if there are not more feature to compute, return node with the most probable class\n",
    "        if len(feature_names) == 0:\n",
    "            node.is_leaf = True\n",
    "            unique_vals, counts = np.unique(y, return_counts=True)\n",
    "            node.label = unique_vals[np.argmax(counts)]\n",
    "            return node\n",
    "\n",
    "        # else choose the feature that maximizes the information gain\n",
    "        best_feature_name = self.get_most_informative_feature(\n",
    "            X, y, feature_names)\n",
    "        node.label = best_feature_name\n",
    "\n",
    "        # value of the chosen feature for each instance\n",
    "        best_feature_id = self.features.tolist().index(best_feature_name)\n",
    "        feature_values = list(set(X[:, best_feature_id]))\n",
    "\n",
    "        for feature_value in feature_values:\n",
    "            branch = [feature_value, Node()]\n",
    "            node.branches.append(branch)\n",
    "\n",
    "            X_subset = X[X[:, best_feature_id] == feature_value]\n",
    "            y_subset = y[X[:, best_feature_id] == feature_value]\n",
    "\n",
    "            if len(X_subset) == 0:\n",
    "                unique_vals, counts = np.unique(y, return_counts=True)\n",
    "                branch[1].label = unique_vals[np.argmax(counts)]\n",
    "            else:\n",
    "                feature_names = [\n",
    "                    a for a in feature_names if a != best_feature_name]\n",
    "                branch[1] = self.decision_tree(X_subset, y_subset, feature_names)\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y, feature_names):\n",
    "        self.features = np.array(feature_names)\n",
    "        self.root = self.decision_tree(np.array(X), np.array(y), feature_names)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self.walk_down(self.root, sample) for sample in X]\n",
    "        return y_pred\n",
    "\n",
    "    def walk_down(self, node, sample):\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "\n",
    "        feature_name = node.label\n",
    "        feature_id = self.features.tolist().index(feature_name)\n",
    "        if node.branches:\n",
    "            for b in node.branches:\n",
    "                if b[0] == sample[feature_id]:\n",
    "                    return self.walk_down(b[1], sample)\n",
    "\n",
    "        return node.label\n",
    "\n",
    "    def print_dt(self):\n",
    "        self.print_recursive(self.root)\n",
    "\n",
    "    def print_recursive(self, node, leading_str=\"\"):\n",
    "        if node.is_leaf:\n",
    "            print(f'class:{node.label}')\n",
    "            return\n",
    "\n",
    "        print(f'({node.label}=?)')\n",
    "        if node.branches:\n",
    "            for b in node.branches:\n",
    "                print(f'{leading_str}  |-- {b[0]} -- ', end=\"\")\n",
    "                new_leading_str = f'{leading_str}  |{\" \" * (len(b[0]) + 7)}'\n",
    "                self.print_recursive(b[1], new_leading_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['No', 'Yes', 'Yes', 'No']\n",
      "Actual: ['Yes' 'Yes' 'Yes' 'No']\n",
      "\n",
      "\n",
      "Decision tree\n",
      "\n",
      "\n",
      "(outlook=?)\n",
      "  |-- Sunny -- (temp=?)\n",
      "  |              |-- Mild -- class:No\n",
      "  |              |-- Hot -- class:No\n",
      "  |              |-- Cool -- class:Yes\n",
      "  |-- Overcast -- class:Yes\n",
      "  |-- Rain -- (wind=?)\n",
      "  |             |-- Weak -- class:Yes\n",
      "  |             |-- Strong -- class:No\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "X = np.array(df.drop(['day', 'play'], axis='columns'))\n",
    "Y = np.array(df['play'])\n",
    "features = df.columns.drop(['day', 'play'])\n",
    "\n",
    "xTrain = X[:10]\n",
    "xTest = X[10:]\n",
    "yTrain = Y[:10]\n",
    "yTest = Y[10:]\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.fit(xTrain, yTrain, features)\n",
    "\n",
    "yPred = tree.predict(xTest)\n",
    "print(f'Predicted: {yPred}')\n",
    "print(f'Actual: {yTest}')\n",
    "\n",
    "tree.print_dt()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
