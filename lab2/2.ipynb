{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_characters = [char for char in '.,/?<>;{[]}|\\\\+=â€“-_!@#$%^&*()\\n']\n",
    "\n",
    "stopWords = []\n",
    "with open('inputs/stopWords.txt', 'r') as stopWords_file:\n",
    "  for row in stopWords_file:\n",
    "    stopWords.append(row.rstrip('\\n\\r'))\n",
    "  stopWords_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordList (fileName: str):\n",
    "  words = set()\n",
    "  with open(fileName, 'r') as input_file:\n",
    "    for word in input_file.read().split():\n",
    "      if word.lower() in stopWords: continue\n",
    "      if word.lower() in ignore_characters: continue\n",
    "      words.add(\"\".join([c.lower() for c in word if c not in ignore_characters]))\n",
    "    input_file.close()\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [f\"inputs/{i}.txt\" for i in range(1, 6)]\n",
    "all_words = set()\n",
    "words_doc_wise = []\n",
    "\n",
    "for file in docs:\n",
    "  words = getWordList(file)\n",
    "  words_doc_wise.append(words)\n",
    "  for word in words:\n",
    "    all_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_present(key: str, words_list: list[str]) -> bool:\n",
    "  for word in words_list:\n",
    "    if (key == word): return True\n",
    "  return False\n",
    "\n",
    "frequency_vector = []\n",
    "for i in range(len(docs)):\n",
    "\tfrequency_arr = []\n",
    "\tfor word in all_words:\n",
    "\t\tif (check_present(word, words_doc_wise[i])): frequency_arr.append(1)\n",
    "\t\telse: frequency_arr.append(0)\n",
    "\tfrequency_vector.append(frequency_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "  return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity b/w Doc 1 & Doc 2: 1.0000\n",
      "Similarity b/w Doc 1 & Doc 3: 0.1568\n",
      "Similarity b/w Doc 1 & Doc 4: 0.0910\n",
      "Similarity b/w Doc 1 & Doc 5: 0.0000\n",
      "Similarity b/w Doc 2 & Doc 3: 0.1568\n",
      "Similarity b/w Doc 2 & Doc 4: 0.0910\n",
      "Similarity b/w Doc 2 & Doc 5: 0.0000\n",
      "Similarity b/w Doc 3 & Doc 4: 0.2247\n",
      "Similarity b/w Doc 3 & Doc 5: 0.0346\n",
      "Similarity b/w Doc 4 & Doc 5: 0.0401\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = []\n",
    "for i in range(4):\n",
    "    temp = []\n",
    "    for j in range(i+1, 5):\n",
    "        temp.append(cosine_similarity(frequency_vector[i], frequency_vector[j]))\n",
    "    cosine_similarities.append(temp)\n",
    "for i in range(4):\n",
    "    for j in range(i + 1, 5):\n",
    "        similarity = cosine_similarities[i][j - (i + 1)]  # list size is decreasing\n",
    "        print(f\"Similarity b/w Doc {i+1} & Doc {j+1}: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
