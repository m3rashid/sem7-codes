{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_characters = [char for char in '.,/?<>;{[]}|\\\\+=-_!@#$%^&*()\\n']\n",
    "\n",
    "stopWords = []\n",
    "with open('inputs/stopWords.txt', 'r') as stopWords_file:\n",
    "  for row in stopWords_file:\n",
    "    stopWords.append(row.rstrip('\\n\\r'))\n",
    "  stopWords_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency (fileName: str):\n",
    "  frequency_vector = dict()\n",
    "  with open(fileName, 'r') as input_file:\n",
    "    for word in input_file.read().split():\n",
    "      if word.lower() in stopWords: continue\n",
    "      if word.lower() in ignore_characters: continue\n",
    "      word = \"\".join([c.lower() for c in word if c not in ignore_characters])\n",
    "      frequency_vector[word] = frequency_vector.get(word, 0) +1\n",
    "  return sorted(frequency_vector.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('variable', 4), ('target', 2), ('exceptionally', 1), ('larger', 1), ('set', 1), ('missing', 1), ('values', 1), ('try', 1), ('excluding', 1), ('modeling', 1), ('need', 1), ('make', 1), ('sure', 1), ('much', 1), ('significant', 1), ('predicting', 1), ('ie', 1), ('correlation', 1), ('dropped', 1), ('low', 1), ('redundant', 1)], [('missing', 2), ('values', 2), ('drop', 2), ('implement', 1), ('strategy', 1), ('handle', 1), ('complete', 1), ('column', 1), ('contains', 1), ('given', 1), ('dataset', 1), ('feature1', 1), ('completely', 1), ('use', 1), ('left', 1), ('features', 1), ('predict', 1), ('target', 1), ('variable', 1)], [('columns', 3), ('missing', 3), ('approach', 1), ('use', 1), ('unsupervised', 1), ('techniques', 1), ('like', 1), ('kmeans', 1), ('hierarchical', 1), ('clustering', 1), ('etc', 1), ('idea', 1), ('skip', 1), ('values', 1), ('consider', 1), ('except', 1), ('target', 1), ('column', 1), ('try', 1), ('create', 1), ('many', 1), ('clusters', 1), ('independent', 1), ('featuresafter', 1), ('drop', 1), ('value', 1), ('finally', 1), ('find', 1), ('category', 1), ('row', 1), ('falls', 1)], [('cluster', 2), ('implement', 1), ('strategy', 1), ('drop', 1), ('feature1', 1), ('column', 1), ('use', 1), ('feature2', 1), ('feature3', 1), ('features', 1), ('new', 1), ('classifier', 1), ('finally', 1), ('formation', 1), ('try', 1), ('observe', 1), ('missing', 1), ('record', 1), ('falling', 1), ('ready', 1), ('final', 1), ('dataset', 1), ('analysis', 1)], [('data', 3), ('complex', 2), ('study', 1), ('pwc', 1), ('found', 1), ('businesses', 1), ('effectively', 1), ('use', 1), ('analytics', 1), ('likely', 1), ('profitable', 1), ('competitive', 1), ('advantage', 1), ('science', 1), ('–', 1), ('art', 1), ('extracting', 1), ('valuable', 1), ('insights', 1), ('sets', 1), ('solving', 1), ('world’s', 1), ('problems', 1), ('agriculture', 1), ('healthcare', 1), ('space', 1), ('sports', 1), ('field', 1)]]\n"
     ]
    }
   ],
   "source": [
    "docs = [f\"inputs/{i}.txt\" for i in range(1, 6)]\n",
    "all_words = set()\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in docs:\n",
    "  freq = count_frequency(file)\n",
    "  data.append(freq)\n",
    "  for tups in freq:\n",
    "    all_words.add(tups[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
